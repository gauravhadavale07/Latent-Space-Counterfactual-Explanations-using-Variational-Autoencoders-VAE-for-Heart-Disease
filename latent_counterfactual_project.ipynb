{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Latent-Space Counterfactual Explanations for Heart Disease Dataset"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nimport torch\nfrom torch import nn\nimport torch.nn.functional as F"]}, {"cell_type": "code", "source": ["df = pd.read_csv('/mnt/data/Cleaned_heart_data3.csv')\n\nX = df.drop('target', axis=1).values\ny = df['target'].values\n\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n\nX_train = torch.tensor(X_train, dtype=torch.float32)\ny_train = torch.tensor(y_train, dtype=torch.long)\nX_test = torch.tensor(X_test, dtype=torch.float32)\ny_test = torch.tensor(y_test, dtype=torch.long)\n\ninput_dim = X.shape[1]"], "metadata": {}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": ["class Classifier(nn.Module):\n    def __init__(self, input_dim, hidden=64):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Linear(input_dim, hidden), nn.ReLU(),\n            nn.Linear(hidden, hidden), nn.ReLU(),\n            nn.Linear(hidden, 2)\n        )\n    def forward(self, x): return self.net(x)\n\nclf = Classifier(input_dim)\nopt_clf = torch.optim.Adam(clf.parameters(), lr=1e-3)\nloss_fn = nn.CrossEntropyLoss()\n\nfor epoch in range(40):\n    clf.train()\n    opt_clf.zero_grad()\n    pred = clf(X_train)\n    loss = loss_fn(pred, y_train)\n    loss.backward()\n    opt_clf.step()"], "metadata": {}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": ["class VAE(nn.Module):\n    def __init__(self, input_dim, latent_dim=8):\n        super().__init__()\n        self.encoder = nn.Sequential(nn.Linear(input_dim,32), nn.ReLU(), nn.Linear(32, latent_dim*2))\n        self.decoder = nn.Sequential(nn.Linear(latent_dim,32), nn.ReLU(), nn.Linear(32,input_dim))\n\n    def encode(self,x):\n        h=self.encoder(x)\n        return h[:,:h.shape[1]//2], h[:,h.shape[1]//2:]\n\n    def sample(self,mu,logvar):\n        std=torch.exp(0.5*logvar)\n        return mu + torch.randn_like(std)*std\n\n    def decode(self,z): return self.decoder(z)\n\n    def forward(self,x):\n        mu,logvar=self.encode(x)\n        z=self.sample(mu,logvar)\n        return self.decode(z),mu,logvar\n\nvae = VAE(input_dim)\nopt_vae = torch.optim.Adam(vae.parameters(), lr=1e-3)\n\ndef vae_loss(x,recon,mu,logvar):\n    recon_loss=((x-recon)**2).mean()\n    kl = -0.5*torch.mean(1+logvar - mu.pow(2) - logvar.exp())\n    return recon_loss + 0.01*kl\n\nfor epoch in range(60):\n    opt_vae.zero_grad()\n    recon,mu,logvar=vae(X_train)\n    loss=vae_loss(X_train,recon,mu,logvar)\n    loss.backward()\n    opt_vae.step()"], "metadata": {}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": ["def generate_cf(x, target_label, steps=600, lr=0.05, lam=1.0):\n    clf.eval(); vae.eval()\n    mu, logvar = vae.encode(x)\n    z = mu.clone().detach(); z.requires_grad=True\n    opt = torch.optim.Adam([z], lr=lr)\n\n    for _ in range(steps):\n        opt.zero_grad()\n        x_cf = vae.decode(z)\n        pred = clf(x_cf)\n        ce = loss_fn(pred, torch.tensor([target_label]))\n        dist = torch.norm(z-mu)\n        loss = lam*ce + dist\n        loss.backward(); opt.step()\n    return vae.decode(z).detach()"], "metadata": {}, "outputs": [], "execution_count": null}, {"cell_type": "code", "source": ["def evaluate_cf(x, cf):\n    x_np, cf_np = x.numpy().flatten(), cf.numpy().flatten()\n    return {\n        'proximity': np.linalg.norm(x_np-cf_np),\n        'sparsity': np.sum(x_np!=cf_np),\n        'realism_mse': np.mean((x_np-cf_np)**2)\n    }\n\ni=5\nx=X_test[i].unsqueeze(0)\npred=torch.argmax(clf(x)).item()\ntarget_label=1-pred\ncf=generate_cf(x,target_label)\n\noriginal=scaler.inverse_transform(x.numpy())\ncounter=scaler.inverse_transform(cf.numpy())\nmetrics=evaluate_cf(x,cf)\n\noriginal, counter, metrics"], "metadata": {}, "outputs": [], "execution_count": null}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.10"}}, "nbformat": 4, "nbformat_minor": 2}